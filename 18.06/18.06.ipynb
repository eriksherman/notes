{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 1: Geometry of Linear equations\n",
    "Ax = b\n",
    "- intersection of lines (row picture) 2:00\n",
    "- 2D linear equation: line\n",
    "- 3D linera equation: plane\n",
    "- Ax is a combination of A's columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 2: elimination with matrices\n",
    "- can succeed or fail (if row of all zeros... then singular matrix)\n",
    "- back substitution 17:38\n",
    "- elimination matrices 2010\n",
    "- A * [1,2,3 in column] -> column of (1*col1 + 2*col2 + 3*col3)\n",
    "- [1,2,3 in row] * A -> row of (1*row1 + 2*row2 + 3*row 3)\n",
    "- Permutation matrix exchanges 2 rows\n",
    "- AB NOT= BA for matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 3: multiplication and inverse matrices\n",
    "- 1:40 matrix multiplication\n",
    "- for square matrices: $A^{-1}A = I = AA^{-1}$\n",
    "- invertable, nonsingular matrices have inverses\n",
    "\t- no inverse means matrix is singular\n",
    "\t- singular matrices A have det(A) = 0\n",
    "\n",
    "Guass-Jordan 36:41\n",
    "\n",
    "<img src=\"assets/guass-jordan.png\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Lecture 4: factorization into $A=Lu$\n",
    "- $E_{21}$ means matrix that transforms $A$ to make $A_{21}$ 0\n",
    "- $EA = u$ possible via row reduction\n",
    "- $L = E^{-1}$\n",
    "- $A = Lu$\n",
    "- $L$ means lower triangular matrix\n",
    "- $u$ means upper triangular matrix\n",
    "\n",
    "Permutation Matrices\n",
    "- property: $P^{-1} = P^{T}$\n",
    "- these are matrices that do row exchanges 44:00\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 5: Transposes, Permutations, spaces $R^n$\n",
    "- $PA = Lu$ is the full picture of reduction... (for any invertible A)\n",
    "- Permutation matrices P are identity matrices with re-ordered rows\n",
    "- \\# of nxn permutations: n!\n",
    "\n",
    "Transposes\n",
    "- all columns in matrix become rows\n",
    "- all rows in matrix become columns\n",
    "- $(A^T)_{ij} = A_{ji}$\n",
    "\n",
    "Symmetric matrices\n",
    "- $A^T = A$\n",
    "- $A^T A$ is always symmetric\n",
    "- $(R^T R)^T = R^T R^{TT}$\n",
    "\n",
    "Vector spaces, subspaces\n",
    "- the set of all vectors closed under vector addition and scalar multiplication\n",
    "- means sum of any two vectors in set is also in the set, scalar multiplication of any vector in the set is also in the set\n",
    "- subspaces of a space R are vector spaces that, for all vectors in the set, R contains them. vectors in subspace are still closed under vector addition, scalar multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 6: Column Space and Null space\n",
    "- $Ax = b$ can be solved when $b$ is a vector in the column space of A, meaning b can be created by taking a combination of the columns of A\n",
    "- \"pivot columns\" are linearly independent columns of a matrix\n",
    "- Nullspace of A is a set of all solutions x such that $Ax=0$\n",
    "- Nullspace is a valid space because...\n",
    "\t- if $Av=0$ and $Aw=0$, $Av + Aw = 0$, $A (v+w) = 0$, $v+w$ also in the space, closed under vector addition\n",
    "\t- if $Av=0$, $cAv=0$ (c is scalar), $A(cv)=0$, $cv$ is also in space, closed under scalar multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 7: Computing the Nullspace\n",
    "- performing elimination doesn't change the nullspace, because row operations are performing legitimate algebra on the equations\n",
    "\t- doesn't change the nullspace or rowspace, does change the columns space\n",
    "- **echelon** - staircase\n",
    "- rank of A: \\# of pivots in echelon form\n",
    "- **pivot columns** contain a pivot and are linearly independent\n",
    "- **free columns** don't contain a pivot\n",
    "- can set the x variables corresponding to these columns as anything\n",
    "- mxn matrix has $r$ pivot cols, $n-r$ free cols\n",
    "- all linear combinations of \"special solutions\" yields general solution to $Ax=0$\n",
    "\t- \"special solutions\" involve setting one of the free vars to one (while the rest are zero) at a time for form basis of Nullspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 8: $Axb$ completely solve linear equations\n",
    "- find one specific solution (could be many) by setting free vars to 0 and solving for pivot vars\n",
    "- add nullspace (combination of \"special solutions\" (making vector of free vars orthogonal... one 1 for the free var at a time and the rest zero))\n",
    "- $x = x_p + x_n$\n",
    "- if $Ax_p = b$ and $Ax_n = 0$, then $A(x_p + x_n) = b$\n",
    "\n",
    "Rank\n",
    "- for mxn matrix A of rank r\n",
    "\t- $r \\leq m$\n",
    "\t- $r \\leq n$\n",
    "- full column rank means r=n\n",
    "\t- pivot in every column... no free vars\n",
    "\t- nullspace only has $\\vec{0}$... no free vars to give special solutions to as basis for the nullspace\n",
    "\t- there exists zero or one ($x_p$) solutions\n",
    "- full row rank means r=m\n",
    "\t- pivots in every row\n",
    "\t- can solve Ax=b for every b\n",
    "\t\t- solution exists\n",
    "\t- left with n-r=n-m free variables\n",
    "- full rank r=m=n\n",
    "\t- invertible matrices\n",
    "\t- row reduced matrix is the identity matrix $R=I$\n",
    "\t- every b has a single unique solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 9: Linear Independence, Spanning a space, Basis and dimension\n",
    "- if A is mxn and m<n\n",
    "\t- more unknowns than equations\n",
    "\t- definitely something in nullspace of A b/c of free vars\n",
    "\n",
    "Independence\n",
    "- vectors $x_1$,$x_2$,...,$x_n$ are independent if no combination gives $\\vec{0}$\n",
    "- columns of A are dependent if there is something in N(A) b/c some nonzero linear combinations of A's columns form $\\vec{0}$\n",
    "- r=n full column rank means columns are independent\n",
    "- r<n means columns of A are dependent\n",
    "\n",
    "Span\n",
    "- vectors $v_1,...,v_l$ **span** a space if the space consists only of combinations of these vectors 19:47\n",
    "- basis for a vector space\n",
    "\t- set of vectors that 1. span a space and 2. are independent of one another\n",
    "- there can be many basis for a vector space, but **all bases for a vector space have the same number of vectors**\n",
    "\t- the number of basis for a vector space is called the dimension of the space 37:00\n",
    "- basis of the column space is the set of pivot columns of A\n",
    "- rank(A)=r=\\# pivot columns= dimension of columns space C(A)\n",
    "- dimension of nullspace of A: \\# free vars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 10\n",
    "4 fundamental spaces (for matrix A)\n",
    "\n",
    "- if rows are dependent, columns are also dependent\n",
    "\n",
    "4 fundamental spaces\n",
    "- column space C(A) in $R^m$ (vectors in columnspace have m components)\n",
    "- nullspace N(A) in $R^n$ (vectors in nullspace have n components)\n",
    "- rowspace R(A) in $R^n$\n",
    "\t- space of all combinations of rows in A\n",
    "\t- also space of all combinations of columns of $A^T$\n",
    "- nullspace of $A^T$ in $R^m$\n",
    "\t- left nullspace of A\n",
    "\n",
    "Gauss-Jordan\n",
    "[$A_{mxn}$ $I_{mxn}$] => [$R$ $E_{mxn}$]\n",
    "- before, $R$ was $I$ and $E$ was $A^{-1}$ (case for nxn)\n",
    "- here, R is row reduced echelon form of A, E is matrix of all row operations to reduce A\n",
    "\t- $EA=R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 11: Matrix spaces, Bases of matrix vector spaces\n",
    "- matrices can be vectors closed under vector addition and scalar multiplication, and can form a vector space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 12: Graphs. skip.\n",
    "Lecture 13: Quiz 1 review. skip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 14: Orthogonal vectors and subspaces\n",
    "\n",
    "Big picture\n",
    "\n",
    "<img src=\"assets/ortho-vector-spaces.png\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orthogonal vectors x, y\n",
    "- $x \\cdot y = 0$\n",
    "- $x^T y = 0$\n",
    "- a subspace S is orthogonal to a subspace T if\n",
    "\t- every vector in s is orthogonal to every vector in T\n",
    "- row space orthogonal to nullspace... every solution to $Ax=0$ multiplies a row and becomes zero\n",
    "\n",
    "\n",
    "<img src=\"assets/row-null.png\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to find best approx. of $Ax=b$ when there is no solution (b isn't in column space)\n",
    "- m > n (too many equations)\n",
    "$A^T A \\hat{x} = A^T b$\n",
    "- $\\hat{x}$ is the best soln."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 15: Projections onto subspaces\n",
    "\n",
    "vector project of b onto a\n",
    "\n",
    "<img src=\"assets/vector-proj.png\" width=\"200px\" />\n",
    "\n",
    "(projection of b onto a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $P=a\\frac{a^T b}{a^T a}= \\frac{a a^T}{a^T a}b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector projection of b onto A\n",
    "- projection matrix P of A is the matrix that, multiplied by b, projects it onto A\n",
    "- # $P = A(A^T A)^{-1}A^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"overconstrained systems\" with n>m (more equations than unknowns) can be approximated with least square \n",
    "- can't solve $Ax=b$... but can solve $A^T A \\hat{x} = A^T b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 16: Projection matrices, least squares\n",
    "- $Pb$ = project b onto **nearest point** in column space\n",
    "- projection kills part of $b$ orthogonal to column space, keeps the part *in* the column space\n",
    "\t- if b in column space, $Pb=b$\n",
    "\t- if b perpendicular to column space, $Pb=\\vec{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b = p + e\n",
    "- p = Pb\n",
    "- e = (I-P)b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 17: Orthonormal vectors, Gram-Schmit A->Q\n",
    "\n",
    "- orthonormal vectors are orthogonal to one another, and size 1\n",
    "- $Q$ = [$q_1$...$q_n$]\n",
    "- if $Q$ is square then $Q^T Q$ = $I$\n",
    "- *normalize* means shrink to standard size (size 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $Q$ has orthogonal columns\n",
    "- Gram-Schmit: how to make a matrix orthogonal...\n",
    "\t- 2 vectors... take one and leave it\n",
    "\t- delete the error part of the other... b = b - proj of b onto a\n",
    "\t- proj of b onto a = $\\frac{ a a^T}{a^T a} b$\n",
    "\n",
    "<img src=\"assets/gram-schmit.png\" width=\"200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A -> Q via Gram-Schmit preserves columns space\n",
    "- analog... $A = Lu$\n",
    "\t- $L$ is a bunch of transformations\n",
    "\t- $u$ is an upper triangular matrix\n",
    "\n",
    "- in this case... $A=QR$\n",
    "\t- $Q$ is orthonormal matrix\n",
    "\t- $R$ is upper triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 18: Properties of determinants\n",
    "1. det($I$) = $1$\n",
    "2. exchange rows: reverse sign of determinant\n",
    "\t- means permutation matrices are either 1 or -1\n",
    "3. det is a linear function of one row\n",
    "\n",
    "<img src=\"assets/rule3.png\" width=\"300px\" />\n",
    "\n",
    "4. 2 equal rows means det=0\n",
    "5. det doesn't change when row reducing\n",
    "\t- det $A$ = det $u$ where $A=Lu$\n",
    "6. row of 0s -> det=0\n",
    "7. det $u$ = product of pivots\n",
    "8. det A = 0 when A is singular\n",
    "9. det(AB) = detA * detB\n",
    "10. det($A^T$) = det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 19: determinant formulas and cofactors\n",
    "\n",
    "Cofactor formula along row 1\n",
    "det A = $a_{11}C_{11} + a_{12}C_{12} +...+ a_{1n}C_{1n}$\n",
    "- $C_{ij}$ is the determinant of A with row i and col j crossed out * 1 if i+j even, -1 if i+j odd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 20: Cramer's rule, inverse matrix, and value\n",
    "$A^{-1} = \\frac{1}{det(A)} C^T$\n",
    "- C is matrix of cofactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 21: Eigenvalues and Eigenvectors\n",
    "eigenvectors are vectors Ax that are parallel to x\n",
    "\n",
    "$Ax = \\lambda v$\n",
    "if A is singular, $\\lambda=0$ is an eigenvalue\n",
    "\t- means it takes a nonzero x and produces $\\vec{0}$\n",
    "- nxn matrices have n eigenvalues\n",
    "- **trace**: sum of $\\lambda$ s = sum of pivots (pivots)\n",
    "- product of $\\lambda$ s = determinant of A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to solve $Ax=\\lambda x$\n",
    "- $Ax = \\lambda x$\n",
    "- $Ax - \\lambda x = 0$\n",
    "- $(A - \\lambda I) x = 0$\n",
    "- therefor $(A - \\lambda I)$ must be singular, its determinant = 0\n",
    "- $|A - \\lambda I| = 0$\n",
    "\t- aka characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 22: diagonalization and powers of A\n",
    "\n",
    "$S^{-1} A S = \\Lambda$\n",
    "- need n independent eigenvectors (to invert S)\n",
    "- $S$ (eigenvector matrix) is matrix of all eigenvectors [$x_1$ $x_2$]\n",
    "- $\\Lambda$ (eigenvalue matrix) is matrix with $\\lambda$ s on diagonal\n",
    "- $AS=S \\Lambda $ is diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $Ax=\\lambda x$\n",
    "- $A^2x=\\lambda Ax = \\lambda ^2 x$\n",
    "- $A^2 = S \\Lambda ^2 S^{-1}$\n",
    "- $A^k = S \\Lambda ^2 S^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A has n independent eigenvectors (and is diagonizable) if all $\\lambda$ s are different\n",
    "- if $\\lambda$ s are not different, A may or may not be diagonizable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- algebraic multiplicity: \\# $\\lambda$ s\n",
    "- geometric multiplicity: \\# eigenvectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ A^{100} u_0 = c_1 \\lambda ^{100} _1 x_1$ + ... (terms that go to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
